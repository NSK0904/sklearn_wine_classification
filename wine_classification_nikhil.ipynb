{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447abf44",
   "metadata": {},
   "source": [
    "# Loading Wine Recognition Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afe181",
   "metadata": {},
   "source": [
    "Firstly I will import datasets from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6630451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8da39c",
   "metadata": {},
   "source": [
    "Then from the sklearn datasets I will load the 'wine' dataset and get its full description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd76882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_data = datasets.load_wine()\n",
    "print(wine_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0e0b1",
   "metadata": {},
   "source": [
    "# Visualize and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b3131",
   "metadata": {},
   "source": [
    "I will now check the shapes of the 'data' and target' fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32bc45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape\t (178, 13) \n",
      "target.shape \t (178,)\n"
     ]
    }
   ],
   "source": [
    "X = wine_data['data']\n",
    "y = wine_data['target']\n",
    "\n",
    "print('data.shape\\t',X.shape,\n",
    "      '\\ntarget.shape \\t',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3829f2",
   "metadata": {},
   "source": [
    "With this it is confirmed that there are 178 samples (rows) and 13 feaures (columns)\n",
    "I will now build a pandas DataFrame, to hold the data so that we can visualize the dataset into a tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c81d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0     0.0  \n",
       "1                            3.40   1050.0     0.0  \n",
       "2                            3.17   1185.0     0.0  \n",
       "3                            3.45   1480.0     0.0  \n",
       "4                            2.93    735.0     0.0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0     2.0  \n",
       "174                          1.56    750.0     2.0  \n",
       "175                          1.56    835.0     2.0  \n",
       "176                          1.62    840.0     2.0  \n",
       "177                          1.60    560.0     2.0  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datawine = pd.DataFrame(data= np.c_[X,y],columns= wine_data['feature_names'] + ['target'])\n",
    "datawine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0216b",
   "metadata": {},
   "source": [
    "With this DataFrame I can check for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d5d4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         0\n",
       "malic_acid                      0\n",
       "ash                             0\n",
       "alcalinity_of_ash               0\n",
       "magnesium                       0\n",
       "total_phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid_phenols            0\n",
       "proanthocyanins                 0\n",
       "color_intensity                 0\n",
       "hue                             0\n",
       "od280/od315_of_diluted_wines    0\n",
       "proline                         0\n",
       "target                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datawine.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b719d963",
   "metadata": {},
   "source": [
    "This confirms that there are no missing values and categorical data\n",
    "The final step to data preprocessing is Feature Scaling. This is done by importing StandardScaler from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f569ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "st_x= StandardScaler()\n",
    "X= st_x.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8eae55",
   "metadata": {},
   "source": [
    "# Split Data For Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec638e83",
   "metadata": {},
   "source": [
    "To train and test our model effectively, we must first separate the data into a training set, which we will feed to our model along with the training labels. The model will then be tested on the 'test' data after it has been trained to determine its real-world applicability.\n",
    "\n",
    "The train test split() method in Scikit-learn comes in handy here. test size specifies how much data is set aside for testing. We want to train our model on enough data to make good predictions, but we also need enough test data to see if we've overfitted the model. Therefore I will choose to test with 20% of the data. This means 80% of data will used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40cf1e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142  samples in training data\n",
      " 36  samples in test data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42 #I chose 42 for random_state as is the most common number used for random_state\n",
    ")\n",
    "\n",
    "print(len(X_train),' samples in training data\\n',\n",
    "      len(X_test),' samples in test data\\n', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e57145",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2921e",
   "metadata": {},
   "source": [
    "I will first create a decision tree classifier object and define a parameter grid for parameter tuning.\n",
    "For the param_grid argument, I created a dictionary and chose 3 parameters used in the Decision Tree Classifer.\n",
    "max-depth for the maximum depth of the tree - default (none)\n",
    "min_samples_split for minimum number of samples required to split an internal node - default (2)\n",
    "min_samples_leaf for minimum number of samples required to be at a leaf node - default (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6650ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [2,3,4,5,6,7],\n",
    "    'min_samples_split': [2,3,4,5,6,7],\n",
    "    'min_samples_leaf': [1,2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485c980",
   "metadata": {},
   "source": [
    "I created a GridSearchCV object and included the estimator, the param_grid and set the K-fold Cross Validation to 5 which is the default for determining the cross-validation splitting strategy. Then I Fit the GridSearchCV object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1af84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, 7],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid = GridSearchCV(dt, param_grid, cv=5)\n",
    "dt_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c585b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  DecisionTreeClassifier(max_depth=3)\n",
      "Best parameters:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", dt_grid.best_estimator_)\n",
    "print(\"Best parameters: \", dt_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc6bb7",
   "metadata": {},
   "source": [
    "As shown above, the Max_depth is chosen as 3. An increasing depth makes a tree model more expressive but a tree too deep will overfit the data, so 3 is good enough for the depth.\n",
    "Min_samples_leaf is chosen as 1 which is the default value.\n",
    "Min_samples_split is chosen as 2 which is the default value.\n",
    "Then the best estimator object is fit to the training data, and the classifier is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db72c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT acc_train: 0.992958\n",
      "DT acc: 0.944444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "best_dt = dt_grid.best_estimator_\n",
    "best_dt.fit(X_train, y_train)\n",
    "y_train_pred_dt = best_dt.predict(X_train)\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, y_train_pred_dt)\n",
    "print(\"DT acc_train: %f\" %acc_train )\n",
    "acc = metrics.accuracy_score(y_test, y_pred_dt)\n",
    "print(\"DT acc: %f\" %acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c3381a",
   "metadata": {},
   "source": [
    "The accuracy score in % for Decision Tree is 94.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48fa094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT recall_train:  [0.97777778 1.         1.        ]\n",
      "DT recall:  [0.92857143 1.         0.875     ]\n"
     ]
    }
   ],
   "source": [
    "recall_train = metrics.recall_score(y_train, y_train_pred_dt, average=None)\n",
    "print(\"DT recall_train: \", recall_train )\n",
    "recall = metrics.recall_score(y_test, y_pred_dt, average=None)\n",
    "print(\"DT recall: \"  ,recall )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d3e424",
   "metadata": {},
   "source": [
    "The recall score is 1 which is the best for class_1 and then followed by class_0 but the score is low for class_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b4b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT precision_train: [1.         0.98275862 1.        ]\n",
      "DT precision: [1.    0.875 1.   ]\n"
     ]
    }
   ],
   "source": [
    "prec_train = metrics.precision_score(y_train, y_train_pred_dt, average=None)\n",
    "print(\"DT precision_train:\", prec_train )\n",
    "prec = metrics.precision_score(y_test, y_pred_dt, average=None)\n",
    "print(\"DT precision:\", prec )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b480e4",
   "metadata": {},
   "source": [
    "The precision score is 1 which is the best for class_2 and class_0 and 0.875 for class_1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ae7efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT f1 train: [0.98876404 0.99130435 1.        ]\n",
      "DT f1: [0.96296296 0.93333333 0.93333333]\n"
     ]
    }
   ],
   "source": [
    "f1_train = metrics.f1_score(y_train, y_train_pred_dt, average=None)\n",
    "print(\"DT f1 train:\", f1_train )\n",
    "f1 = metrics.f1_score(y_test, y_pred_dt, average=None)\n",
    "print(\"DT f1:\", f1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477233f",
   "metadata": {},
   "source": [
    "The F1 score is best in class_0, followed by decent scores in both class_1 and class_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15893f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT conf_mat: %f\n",
      "[[13  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  1  7]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"DT conf_mat: %f\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1ac69",
   "metadata": {},
   "source": [
    "Based on all the scores a classification report can be generated for the Decision Tree Classification Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12b68077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9286    0.9630        14\n",
      "           1     0.8750    1.0000    0.9333        14\n",
      "           2     1.0000    0.8750    0.9333         8\n",
      "\n",
      "    accuracy                         0.9444        36\n",
      "   macro avg     0.9583    0.9345    0.9432        36\n",
      "weighted avg     0.9514    0.9444    0.9449        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classification Report:\\n\", metrics.classification_report(y_test, y_pred_dt, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b86987",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02394fce",
   "metadata": {},
   "source": [
    "I will first create a random classifier object and define a parameter grid for parameter tuning.\n",
    "For the param_grid argument, I created a dictionary and chose 3 parameters used in the Random Forest Classifer.\n",
    "criterion to measure the quality of a split - default (gini)\n",
    "max-depth for the maximum depth of the tree - default (none)\n",
    "n-estimators for the number of trees in the forest - default (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ebf970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_grid1 = {\n",
    "    'n_estimators': [10,30,50, 100, 150,200,300],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111687a6",
   "metadata": {},
   "source": [
    "I created a GridSearchCV object and included the estimator, the param_grid and set the K-fold Cross Validation to 5 which is the default for determining the cross-validation splitting strategy. Then I Fit the GridSearchCV object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c42f6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'n_estimators': [10, 30, 50, 100, 150, 200, 300]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid=param_grid1, cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a11a0efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  RandomForestClassifier(criterion='entropy', max_depth=5)\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", grid_search.best_estimator_)\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06266c3",
   "metadata": {},
   "source": [
    "As shown above, the criterion is chosen as entropy which is not the default (Gini).\n",
    "Max_depth is chosen as 5. An increasing depth makes a tree model more expressive but a tree too deep will overfit the data, so 5 is good enough for the depth.\n",
    "N_estimators is chosen as 100 which is the default value. Increasing the number of trees can improve the performance of the classifier but also increases the computational cost.\n",
    "Then the best estimator object is fit to the training data, and the classifier is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "320859bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF acc_train: 1.000000\n",
      "RF acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_train_pred_rf = best_rf.predict(X_train)\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, y_train_pred_rf)\n",
    "print(\"RF acc_train: %f\" %acc_train )\n",
    "acc = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "print(\"RF acc: %f\" %acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f3eaa",
   "metadata": {},
   "source": [
    "The accuracy score for Random Forest Classifier in % is 100, which is absolute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f03fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF recall_train: [1. 1. 1.]\n",
      "RF recall: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "recall_train = metrics.recall_score(y_train, y_train_pred_rf, average=None)\n",
    "print(\"RF recall_train:\", recall_train )\n",
    "recall = metrics.recall_score(y_test, y_pred_rf, average=None)\n",
    "print(\"RF recall:\", recall )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496defe",
   "metadata": {},
   "source": [
    "The recall scores are best in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0749d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF precision_train: [1. 1. 1.]\n",
      "RF precision: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "prec_train = metrics.precision_score(y_train, y_train_pred_rf, average=None)\n",
    "print(\"RF precision_train:\", prec_train )\n",
    "prec = metrics.precision_score(y_test, y_pred_rf, average=None)\n",
    "print(\"RF precision:\", prec )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a0675",
   "metadata": {},
   "source": [
    "The precision scores are best in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f7075a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF f1 train: [1. 1. 1.]\n",
      "RF f1: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "f1_train = metrics.f1_score(y_train, y_train_pred_rf, average=None)\n",
    "print(\"RF f1 train:\", f1_train )\n",
    "f1 = metrics.f1_score(y_test, y_pred_rf, average=None)\n",
    "print(\"RF f1:\", f1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa5585",
   "metadata": {},
   "source": [
    "The F1 scores are best in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f03086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF conf_mat:\n",
      "[[14  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"RF conf_mat:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e626547",
   "metadata": {},
   "source": [
    "Based on all the scores a classification report can be generated for the Random Forest Classification Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "121adfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        14\n",
      "           1     1.0000    1.0000    1.0000        14\n",
      "           2     1.0000    1.0000    1.0000         8\n",
      "\n",
      "    accuracy                         1.0000        36\n",
      "   macro avg     1.0000    1.0000    1.0000        36\n",
      "weighted avg     1.0000    1.0000    1.0000        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classification Report:\\n\", metrics.classification_report(y_test, y_pred_rf, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cca513",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab255ea",
   "metadata": {},
   "source": [
    "I will first create a SVC classifier object and define a parameter grid for parameter tuning.\n",
    "For the param_grid argument, I created a dictionary and chose 3 parameters used in the Decision Tree Classifer.\n",
    "C is a Regularization parameter - default (1)\n",
    "kernel Specifies the kernel type to be used in the algorithm - default (rbf)\n",
    "gamma is the Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’ - default(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcc57581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svmc = SVC()\n",
    "\n",
    "param_grid2 = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc20e3",
   "metadata": {},
   "source": [
    "I created a GridSearchCV object and included the estimator, the param_grid and set the K-fold Cross Validation to 5 which is the default for determining the cross-validation splitting strategy. Then I Fit the GridSearchCV object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bf99c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2 = GridSearchCV(svmc, param_grid=param_grid2, cv=5)\n",
    "grid_search2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b47f35dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get parameters:  SVC(C=1, kernel='sigmoid')\n",
      "Best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Get parameters: \", grid_search2.best_estimator_)\n",
    "print(\"Best parameters:\", grid_search2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9ef66",
   "metadata": {},
   "source": [
    "As shown above, the C value is chosen as 1 which is the default value.\n",
    "Kernel is sigmoid so this function is equivalent to a two-layer, perceptron model of the neural network, which is used as an activation function for artificial neurons.\n",
    "Gamma is chosen as scale which is the default value.\n",
    "Then the best estimator object is fit to the training data, and the classifier is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acbcf79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC acc_train: 0.9788732394366197\n",
      "SVC acc: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "best_svc = grid_search2.best_estimator_\n",
    "best_svc.fit(X_train, y_train)\n",
    "y_train_pred_svc = best_svc.predict(X_train)\n",
    "y_pred_svc = best_svc.predict(X_test)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, y_train_pred_svc)\n",
    "print(\"SVC acc_train:\", acc_train )\n",
    "acc = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "print(\"SVC acc:\", acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7b409",
   "metadata": {},
   "source": [
    "The accuracy score for SVC in % is 97.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89fb4165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC recall_train: [1.         0.94736842 1.        ]\n",
      "SVC recall: [1.         0.92857143 1.        ]\n"
     ]
    }
   ],
   "source": [
    "recall_train = metrics.recall_score(y_train, y_train_pred_svc, average=None)\n",
    "print(\"SVC recall_train:\", recall_train )\n",
    "recall = metrics.recall_score(y_test, y_pred_svc, average=None)\n",
    "print(\"SVC recall:\", recall )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827d7b2",
   "metadata": {},
   "source": [
    "The recall score is best with class_0 and class_2, and decent with class_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fceeee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC precision_train: [0.97826087 1.         0.95238095]\n",
      "SVC precision: [1.         1.         0.88888889]\n"
     ]
    }
   ],
   "source": [
    "prec_train = metrics.precision_score(y_train, y_train_pred_svc, average=None)\n",
    "print(\"SVC precision_train:\", prec_train )\n",
    "prec = metrics.precision_score(y_test, y_pred_svc, average=None)\n",
    "print(\"SVC precision:\", prec )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea0931",
   "metadata": {},
   "source": [
    "The precision score is best with class_0 and class_1, however low with class_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91f64916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC f1 train: [0.98901099 0.97297297 0.97560976]\n",
      "SVC f1: [1.         0.96296296 0.94117647]\n"
     ]
    }
   ],
   "source": [
    "f1_train = metrics.f1_score(y_train, y_train_pred_svc, average=None)\n",
    "print(\"SVC f1 train:\", f1_train )\n",
    "f1 = metrics.f1_score(y_test, y_pred_svc, average=None)\n",
    "print(\"SVC f1:\", f1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae81c4",
   "metadata": {},
   "source": [
    "The F1 score is best with class_0, followed by class_1 and finally class_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d44761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC conf_mat: %f\n",
      "[[14  0  0]\n",
      " [ 0 13  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"SVC conf_mat: %f\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd331a0",
   "metadata": {},
   "source": [
    "Based on all the scores a classification report can be generated for the SVM Classification Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b23d8ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        14\n",
      "           1     1.0000    0.9286    0.9630        14\n",
      "           2     0.8889    1.0000    0.9412         8\n",
      "\n",
      "    accuracy                         0.9722        36\n",
      "   macro avg     0.9630    0.9762    0.9680        36\n",
      "weighted avg     0.9753    0.9722    0.9725        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Classification Report:\\n\", metrics.classification_report(y_test, y_pred_svc, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f899e2e",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f6d42",
   "metadata": {},
   "source": [
    "I will first create a KNN Classifier object and define a parameter grid for parameter tuning.\n",
    "For the param_grid argument, I created a dictionary and chose 3 parameters used in the Random Forest Classifer.\n",
    "n_neighbors used for the number of neighbors to use - default (5)\n",
    "weights function is used for prediction - default (uniform)\n",
    "p is the power parameter for the Minkowski Metric - default (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d35043fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "param_grid3 = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'p': [1, 2],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e59b3f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [3, 5, 7, 9], 'p': [1, 2],\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3 = GridSearchCV(knn_clf, param_grid=param_grid3, cv=5)\n",
    "grid_search3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131bec9",
   "metadata": {},
   "source": [
    "I created a GridSearchCV object and included the estimator, the param_grid and set the K-fold Cross Validation to 5 which is the default for determining the cross-validation splitting strategy. Then I Fit the GridSearchCV object to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc71bd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  KNeighborsClassifier(p=1)\n",
      "Best Parameters: {'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", grid_search3.best_estimator_)\n",
    "print(\"Best Parameters:\", grid_search3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf83b73",
   "metadata": {},
   "source": [
    "As shown the best parameters were 5 which is the default for n_neighbors, 1 for p which uses manhattan_distance and uniform which is the default value for weights. Then the best estimator object is fit to the training data, and the classifier is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "890ff657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN acc_train: 0.9859154929577465\n",
      "kNN acc: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "best_knn = grid_search3.best_estimator_\n",
    "best_knn.fit(X_train, y_train)\n",
    "y_train_pred_knn = best_knn.predict(X_train)\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, y_train_pred_knn)\n",
    "print(\"kNN acc_train:\", acc_train )\n",
    "acc = metrics.accuracy_score(y_test, y_pred_knn)\n",
    "print(\"kNN acc:\", acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8b169",
   "metadata": {},
   "source": [
    "The accuracy score in % for kNN is 94.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b5a01d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN recall_train: [1.         0.96491228 1.        ]\n",
      "kNN recall: [1.         0.85714286 1.        ]\n"
     ]
    }
   ],
   "source": [
    "recall_train = metrics.recall_score(y_train, y_train_pred_knn, average=None)\n",
    "print(\"kNN recall_train:\", recall_train)\n",
    "recall = metrics.recall_score(y_test, y_pred_knn, average=None)\n",
    "print(\"kNN recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0430c40",
   "metadata": {},
   "source": [
    "The recall score is best in class_0 and class class_2, but low in class_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bf48c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN precision_train: [0.97826087 1.         0.97560976]\n",
      "kNN precision: [0.93333333 1.         0.88888889]\n"
     ]
    }
   ],
   "source": [
    "prec_train = metrics.precision_score(y_train, y_train_pred_knn, average=None)\n",
    "print(\"kNN precision_train:\", prec_train )\n",
    "prec = metrics.precision_score(y_test, y_pred_knn, average=None)\n",
    "print(\"kNN precision:\", prec )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695138f",
   "metadata": {},
   "source": [
    "The Precision score is best in class_1 followed by class_0 and then class_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd32cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN f1 train: [0.98901099 0.98214286 0.98765432]\n",
      "kNN f1: [0.96551724 0.92307692 0.94117647]\n"
     ]
    }
   ],
   "source": [
    "f1_train = metrics.f1_score(y_train, y_train_pred_knn, average=None)\n",
    "print(\"kNN f1 train:\", f1_train )\n",
    "f1 = metrics.f1_score(y_test, y_pred_knn, average=None)\n",
    "print(\"kNN f1:\", f1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efddc3d8",
   "metadata": {},
   "source": [
    "The F1 score is best in class_0, followed by class_2 and finally class_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec458f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Confusion Matrix:\n",
      "[[14  0  0]\n",
      " [ 1 12  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"kNN Confusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619817fb",
   "metadata": {},
   "source": [
    "Based on all the scores a classification report can be generated for the Decision Tree Classification Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "868620fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9333    1.0000    0.9655        14\n",
      "           1     1.0000    0.8571    0.9231        14\n",
      "           2     0.8889    1.0000    0.9412         8\n",
      "\n",
      "    accuracy                         0.9444        36\n",
      "   macro avg     0.9407    0.9524    0.9433        36\n",
      "weighted avg     0.9494    0.9444    0.9436        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Nearest Neighbors Classification Report:\\n\", metrics.classification_report(y_test, y_pred_knn, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e43d04",
   "metadata": {},
   "source": [
    "# Accuracy, Precision, Recall, F1 Scores and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570b46b",
   "metadata": {},
   "source": [
    "Accuracy is the ratio of correct predictions out of all predictions made by an algorithm. It can be calculated by dividing precision by recall or as 1 minus false negative rate (FNR) divided by false positive rate (FPR).\n",
    "\n",
    "Accuracy = ((TP + TN)) / ((TP + FP + TN + FN))\n",
    "\n",
    "The Precision is the ratio of true positives over the sum of false positives and true negatives. It is also known as positive predictive value. Precision is a useful metric and shows that out of those predicted as positive, how accurate the prediction was.\n",
    "\n",
    "Precision = ((TP)/(TP + FP)) = ((TP)/(Total Predicted Positive))\n",
    "\n",
    "Recall is the ratio of correctly predicted outcomes to all predictions. It is also known as sensitivity or specificity. Recall is just the proportion of positives our model are able to catch through labelling them as positives. When the cost of False Negative is greater than that of False Positive, we should select our best model using Recall.\n",
    "\n",
    "Recall = ((TP)/(TP + FN)) = ((TP)/(Total Actual Positive))\n",
    "\n",
    " F1 score is a weighted average of precision and recall. As we know in precision and in recall there is false positive and false negative so it also consider both of them. F1 score is usually more useful than accuracy, especially if you have an uneven class distribution\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "The confusion matrix is a table that summarizes how successful the classification model is at predicting examples belonging to various classes. One axis of the confusion matrix is the label that the model predicted, and the other axis is the actual label.  We can use confusion matrix when we compare different model by looking how well it predicted a true positive(TP) and true negative(TN). If one model predicted a TP and TN very well than other model then we choose this model as our base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57643b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e32db",
   "metadata": {},
   "source": [
    "The highest accuracy was achieved by the Random Forest Classifier - 100% accuracy\n",
    "The 2nd highest accuracy was achieved by Support Vector Machines -  97.2% accuracy\n",
    "The 3rd highest accuracy was achieved by both Decision Tree & K-Nearest Neighbors classifiers - 94.4% accuracy\n",
    "\n",
    "I believe that tuning the parameters affected the evaluation and performance of the classification models, and with GridSearchCV the best parameters were chosen for each algorithm for the best results.\n",
    "\n",
    "Additionally from observing the Precision, Recall and F1 Scores of each classification models, it is seen that Random Forest Classifier performs best once again in all classes. This is followed by Support Vector Machines, then Decision Tree Classiifer & K-Nearest Neighbors, with a slightly better average score in Decision Tree Classifier.\n",
    "\n",
    "In conclusion, it is safe to say that Random Forest Classifer obtains absolute accuracy making it the best classfication model, followed by SVM, K-Nearest Neighbors and finally Decision Tree Classifers with pretty decent accuracy scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
